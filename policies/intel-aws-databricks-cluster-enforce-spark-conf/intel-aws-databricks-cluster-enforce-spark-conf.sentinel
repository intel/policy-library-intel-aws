import "tfplan/v2" as tfplan

param valid_actions default [
	["no-op"],
	["create"],
	["update"],
]

format = {
	"reset": "\033[0m",
	"info":  "\033[32m",
	"warn":  "\033[33m",
	"error": "\033[31m",
}

summary = func(input, level) {
	result = false
	if input.violations is empty {
		return true
	} else {
		log(input, format[level])
	}
	return result
}

log = func(input, output) {
	header(input, output)
	violations(input, output)
	return null
}

header = func(input, output) {
	print(
		output + "\t========================================================================\n",
		output + "\t                    _       _       _ \n",
		output + "\t                   (_)     | |     | |\n",
		output + "\t                    _ _ __ | |_ ___| |\n",
		output + "\t                   | | '_ \\| __/ _ \\ |\n",
		output + "\t                   | | | | | ||  __/ |\n",
		output + "\t                   |_|_| |_|\\__\\___|_|\n",
		output + "\t\n",
		output + "\t========================================================================\n",
		output + "\tName        :" + output + " " + "intel-aws-databricks-cluster-enforce-spark-conf.sentinel\n",
		output + "\tCategory    :" + output + " " + "Platform (PaaS)\n",
		output + "\tProvider    :" + output + " " + "databricks/databricks\n",
		output + "\tResource    :" + output + " " + "databricks_cluster\n",
		output + "\tParameter   :" + output + " " + "spark_conf\n",
		output + "\tCheck       :" + output + " " + "spark_conf is not null\n",
		output + "\t\n",
	)
	return null
}

violations = func(input, output) {
	print(
		output + "\t========================================================================\n",
		output + "\tRESOURCE VIOLATIONS\n" + format.reset,
		output + "\tThe configured databricks cluster should use optimization scripts\n",
		output + "\t========================================================================\t",
	)
	for input.violations as violation {
		print(
			"\t",
			output + "name       :" + output + " " + violation.name + "\n\t",
			output + "type       :" + output + " " + violation.type + "\n\t",
			output + "address    :" + output + " " + violation.address + "\n\t",
			output + "message    :" + output + " " + violation.message + "\t\n",
			output + "\t------------------------------------------------------------------------\t",
		)
	}
	if (input.violations is not empty) {
		print(
			output + "\t",
			output + "Resources out of compliance: " + string(length(input.violations)) + "\n" + format.reset,
			output + "\t------------------------------------------------------------------------\t",
		)
	}
	return null
}

doc = {
	"id":       "dbxoptimizedcluster",
	"resource": "databricks_cluster",
	"name":     "Optimizations scripts must be enabled",
}

// Filter resources by type
all_resources = filter tfplan.resource_changes as _, rc {
	rc.type is doc.resource and
		rc.mode is "managed" and
		rc.change.actions in valid_actions
}

// Filter resources that violate a given condition
violators = filter all_resources as _, r {
	r.change.after.spark_conf is null
}

// Build a summary report
summaryreport = {
	"id":   doc.id,
	"name": doc.name,
	"violations": map violators as _, violation {
		{
			"name":    violation.name,
			"address": violation.address,
			"type":    violation.type,
			"message": violation.name + " has no optimization scripts.",
		}
	},
}

main = rule {
	summary(summaryreport, "warn")
}
